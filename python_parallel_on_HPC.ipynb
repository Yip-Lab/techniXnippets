{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel on HPCs with `ipyparallel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not very common to face extremely heavy computational tasks in bioinformatics study. However, when we really encounter one, it's pain as hell. Nobody like to wait a task that cost more than 24 hrs, especially when knowing that the result might not be enlightening. Parallel computing definitely helps in such scenario: if you can properly split the task and distribute them on different cores, with enough CPUs the runtime could be reduced drastically. In this snippet, I will introduce a package in Python that made parallelization eazy and sweet--`ipyparallel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale\n",
    "There are multiple libraries for doing parallel computing in python, why should we care about this one (given that it has such a long weired name)? There are two main reasons: \n",
    "1. It allows you to distribute tasks not only locally on multiple cores, but also across machines that's in the same network. That means you can utilize 10 cores on each hpc in our server using **one single command**. \n",
    "2. It has good integration with jupyter notebook. In fact it's a spin-off from the original ipython project. `ipython-notebook` evolves into `jupyter notebook`, while `IPython.parallel` becomes into `ipyparallel`. When you open a jupyter notebook, on the root page you see 3 tabs: \"Files\", \"Running\", and \"Clusters\". The \"Clusters\" tab will provide you the realtime information for your current `ipyparallel` session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "- The Docs of `ipyparallel` is in https://ipyparallel.readthedocs.io/en/latest/intro.html. \n",
    "- The installation can be easily performed using `pip install ipyparallel` or `conda install ipyparallel`.\n",
    "- The \"visible\" components in the `ipyparallel` include:\n",
    "    - Cluster\n",
    "        - One Controller (the commander)\n",
    "        - Multiple engines (the workforce)\n",
    "    - Client(s) (the main interactive python session)\n",
    "- Settings, including settings for Controller/Engines are stored in `~/.ipython/profile_{default}/*.py`. There could be multiple setting \"profiles\": For example, for one particular task, you might need 20 cores on hpc1-5; for another task, you might need 160 cores spread across hpc1-12. You can then setup two profiles for these tasks correspondingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (one HPC only)\n",
    "1. Use `ipcluster start -n 4` to start a controller and 4 engines on local machine (with default profile), each engines would correspond to one CPU.\n",
    "2. After the command line output says `Engines appear to have started successfully`, open a `ipython/jupyter` session and try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ipyparallel\n",
    "import ipyparallel as ipp\n",
    "# start a client in this python session\n",
    "c = ipp.Client()\n",
    "# client will automatically identify the controller (on the same machine, with the default profile)\n",
    "# list ids of engines\n",
    "c.ids\n",
    "# Out[3]: [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, World', 'Hello, World', 'Hello, World', 'Hello, World']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:].apply_sync(lambda : \"Hello, World\")\n",
    "# Out[4]: [ 'Hello, World', 'Hello, World', 'Hello, World', 'Hello, World' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (multiple HPCs)\n",
    "0. For convenience's sake, it's better to setup passwork-less ssh login between different HPCs. You can do that by `ssh-keygen` on each HPCs using a prefix like `hpcN(N=1,2,3...)` and `cat ~/.ssh/hpcN.pub >> ~/.ssh/authorized_keys` to append the public keys to the trusted list.\n",
    "\n",
    "1. Create a new profile PROFILE: `ipython profile create --parallel --profile=PROFILE`\n",
    "1. Setup the config file for ipcluster: un-comment or add the following lines in `~/.ipython/profile_PROFILE/ipcluster_config.py`:\n",
    "\n",
    "```python\n",
    "c.IPClusterEngines.engine_launcher_class = 'SSH'\n",
    "c.IPClusterStart.controller_launcher_class = 'Local'\n",
    "c.SSHLauncher.to_fetch = []\n",
    "c.SSHLauncher.to_send = []\n",
    "c.SSHClusterLauncher.remote_profile_dir = '/data/d0/gds/USERNAME/.ipython/profile_PROFILE'\n",
    "c.SSHEngineSetLauncher.engines = {\n",
    "    # specify the hostname of hpc you want to use and the corresponding number of cores\n",
    "    'hpc7': 10,\n",
    "    'hpc8': 10,\n",
    "    'hpc9': 10,\n",
    "    'hpc10': 10,\n",
    "    'hpc11': 10,\n",
    "    'hpc12': 10,\n",
    "    'hpc13': 10,\n",
    "    'hpc14': 10,\n",
    "    'hpc15': 10\n",
    "}\n",
    "c.SSHEngineSetLauncher.engine_cmd = [\n",
    "    # modify this to your /path/to/bin/of/ipengine, you can `which ipengine`\n",
    "    '/path/to/ipengine'\n",
    "]\n",
    "c.SSHEngineSetLauncher.engine_args = ['--profile=PROFILE']\n",
    "\n",
    "```  \n",
    "   \n",
    "2. Setup the config file for controllers: un-comment or add the following lines in `~/.ipython/profile_PROFILE/ipcontroller_config.py`:\n",
    "\n",
    "```python\n",
    "c.HubFactory.client_ip = '*'\n",
    "c.HubFactory.engine_ip = '*'\n",
    "c.HubFactory.monitor_ip = '*'\n",
    "```\n",
    "\n",
    "3. Use `ipcluster start --profile=='PROFILE'` to start the specified profile\n",
    "4. Open a client python session as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipyparallel\n",
    "import ipyparallel as ipp\n",
    "# start a client in this python session\n",
    "c = ipp.Client(profile='PROFILE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import in engines\n",
    "It's common to use other libraries in computation. For example, to import `numpy` on both engines and clients, use `sync_imports`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing numpy on engine(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1.15.0', ['1.15.0', '1.15.0', '1.15.0', '1.15.0']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview = c[:] #direct view interface, see https://ipyparallel.readthedocs.io/en/latest/direct.html \n",
    "with dview.sync_imports():\n",
    "    import numpy\n",
    "    \n",
    "[numpy.version.version, c[:].apply_sync(lambda : numpy.version.version)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push\n",
    "Memories are not shared across engines and clients. Thus, sometimes we need to send the data objects and functions to engines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4,5])\n",
    "def print_sum(arr):\n",
    "    s = arr.sum()\n",
    "    print(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "push a and print_sum to all engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview.push(dict(\n",
    "    print_sum=print_sum, # format: name_in_engines=name_in_current_client\n",
    "    a=a\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a on all engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5]),\n",
       " array([1, 2, 3, 4, 5]),\n",
       " array([1, 2, 3, 4, 5]),\n",
       " array([1, 2, 3, 4, 5])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also `pull` back variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5]),\n",
       " array([1, 2, 3, 4, 5]),\n",
       " array([1, 2, 3, 4, 5]),\n",
       " array([1, 2, 3, 4, 5])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.pull('a').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync and async call\n",
    "`apply` and `map` function have two versions: `sync` and `async`.\n",
    "`sync` call will block the current client session and wait until all results been transmit back to the client, the result is return directly by the call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 15, 15, 15]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.apply_sync(lambda x : print_sum(x), a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`async` call will not block current session, the results need to be queried using `.get()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: <lambda>>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_result = dview.apply_async(lambda x : print_sum(x), a)\n",
    "async_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 15, 15, 15]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_result.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `scatter` and `gather`\n",
    "Sometimes we have a long list of objects and we'd like to have some divide-and-conquer, `scatter` can help us distribute an list of objects across engines, while `gather` helps us to collect results back from engines, and flatten them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = numpy.array([1,2,3,4,5,6,7,8,9])\n",
    "def print_sum(arr):\n",
    "    s = arr.sum()\n",
    "    print(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: scatter>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.scatter('bpart', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3]), array([4, 5]), array([6, 7]), array([8, 9])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview['bpart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.gather('bpart').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 9, 13, 17]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.execute('bpart_sum=print_sum(bpart)')\n",
    "dview.gather('bpart_sum').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dview.gather('bpart_sum').get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipython magic commands\n",
    "In short, use `%px` before commands you want to run in engines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] [1 2 3]\n",
      "[stdout:1] [4 5]\n",
      "[stdout:2] [6 7]\n",
      "[stdout:3] [8 9]\n"
     ]
    }
   ],
   "source": [
    "%px print(bpart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehension parallelization\n",
    "List comprehension is a commonly used grammar sugar in python. We can use `scatter` and `gather` with list comprehension for parallel computing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 8, 27, 64, 125, 216, 343, 512, 729, 1000, 1331, 1728, 2197, 2744, 3375]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview.scatter('x',range(16))\n",
    "%px y = [i**3 for i in x]\n",
    "y = dview.gather('y')\n",
    "y.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
